{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Fine-Tuning Sentence Classification for CoLA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNVvOP42UJpIsBw75telssX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ca6c96f06abc4bb18ac400b5e0474ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aefd1c49a92b47ba988694dc76083b62",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4f05d2380d3343019aae135e4f9bf2e4",
              "IPY_MODEL_8bd35671bbd1447a9af1fbe62f38543f"
            ]
          }
        },
        "aefd1c49a92b47ba988694dc76083b62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f05d2380d3343019aae135e4f9bf2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8ba0eac1a72a42a1a53d792d33a6fc01",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a04e86597e9c4dbb9e4aa71349e0b014"
          }
        },
        "8bd35671bbd1447a9af1fbe62f38543f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d16de7ccbfc94963ae5ffc428e4c804f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.83kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f1125b92c5d4f8e970916e43aee47b1"
          }
        },
        "8ba0eac1a72a42a1a53d792d33a6fc01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a04e86597e9c4dbb9e4aa71349e0b014": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d16de7ccbfc94963ae5ffc428e4c804f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f1125b92c5d4f8e970916e43aee47b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0ce716a83eb242708b23d5b7970f452c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f716c292cad646ecaec1e075dd15252e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f2eabd1f35844d56bbcccc6ba78e0be1",
              "IPY_MODEL_d63f6b7d33dd4a5fa693eb3db19c4dea"
            ]
          }
        },
        "f716c292cad646ecaec1e075dd15252e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2eabd1f35844d56bbcccc6ba78e0be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f329deb5e5014a17b17fbcc5a03eadfd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6dbb3260140b415eb4de49801f2ac03c"
          }
        },
        "d63f6b7d33dd4a5fa693eb3db19c4dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b89bdf978af3496b99a2af6e4b8b7bfa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:33&lt;00:00, 13.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_34144b4a2b06438cab9282d307006d79"
          }
        },
        "f329deb5e5014a17b17fbcc5a03eadfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6dbb3260140b415eb4de49801f2ac03c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b89bdf978af3496b99a2af6e4b8b7bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "34144b4a2b06438cab9282d307006d79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamedAteya/BERT-Fine-Tuning-Sentence-Classification-for-CoLA/blob/master/BERT_Fine_Tuning_Sentence_Classification_for_CoLA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoG3e4KVgEUl"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tapUVOYgIIF"
      },
      "source": [
        "## Check for GPUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYWKkjfpfkr7",
        "outputId": "d2c969a6-f01a-4d99-f64f-13cc96058f5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2Hm00BOgNJV",
        "outputId": "49fbde26-b07a-43cf-8e56-1cdf4132ca1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIZ3Qqh9g2Y1"
      },
      "source": [
        "## Install transformers Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sICMxy_gsM2",
        "outputId": "37524f91-e55d-415d-eb4e-4f944015e57a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JABTDVyNhTXm"
      },
      "source": [
        "# Loading CoLA Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-n0y17WhyAj"
      },
      "source": [
        "The Corpus of Linguistic Acceptability (CoLA) dataset for single sentence classification. It's a set of sentences labeled as grammatically correct or incorrect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN8VXXxIhB-e",
        "outputId": "fe4945d4-b688-438b-e5bf-78716b7d28c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgWoyYvWh6KH",
        "outputId": "ec02377f-e244-4d0a-d7f3-e869e31c57d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v8vn7I2iBXO"
      },
      "source": [
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Usm8eM-kiIkb",
        "outputId": "9eaffaea-a1c2-445c-b273-28686640edbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our friends won't buy this analysis, let alone...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>One more pseudo generalization and I'm giving up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>One more pseudo generalization or I'm giving up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The more we study verbs, the crazier they get.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Day by day the facts are getting murkier.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentence_source  ...                                           sentence\n",
              "0            gj04  ...  Our friends won't buy this analysis, let alone...\n",
              "1            gj04  ...  One more pseudo generalization and I'm giving up.\n",
              "2            gj04  ...   One more pseudo generalization or I'm giving up.\n",
              "3            gj04  ...     The more we study verbs, the crazier they get.\n",
              "4            gj04  ...          Day by day the facts are getting murkier.\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naNAQVuKir2k"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgeUyxHNjK6K"
      },
      "source": [
        "# Tokenization & Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oWTZ_85j10q"
      },
      "source": [
        "1. Add special tokens to the start and end of each sentence.\n",
        "2. Pad & truncate all sentences to a single constant length.\n",
        "3. Explicitly differentiate real tokens from padding tokens with the \"attention mask\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5T7W6jjPjFdo"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4akZs4ejU60",
        "outputId": "d6033ee0-bf7c-4677-d0cd-f2e93a17878c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "\n",
        "for sent in sentences:\n",
        "\n",
        "    encoded_sent = tokenizer.encode( sent, add_special_tokens = True)\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: [101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg0Fzne_l3H1",
        "outputId": "b64d80c7-1c48-4140-c741-a3c0ff9bfe38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Max length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length:  47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o9Wa3afl85_"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the maximum training sentence length of 47...\n",
        "MAX_LEN = 64\n",
        "\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBrvzJe_ms8V"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7Ir9cmwnU42"
      },
      "source": [
        "# Train and Validation sets split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr3s-ITEnGOH"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=13, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=13, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sycac1z7oIRk"
      },
      "source": [
        "# DataLoader preperation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQjEMaIHnuQL"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JKmBGEAn162"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqUmd_hcosJp"
      },
      "source": [
        "# Train Classification model (BertForSequenceClassification)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5VbPeKgobhB",
        "outputId": "3e138531-0f60-41c1-949b-28ebfc1b70f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ca6c96f06abc4bb18ac400b5e0474ab2",
            "aefd1c49a92b47ba988694dc76083b62",
            "4f05d2380d3343019aae135e4f9bf2e4",
            "8bd35671bbd1447a9af1fbe62f38543f",
            "8ba0eac1a72a42a1a53d792d33a6fc01",
            "a04e86597e9c4dbb9e4aa71349e0b014",
            "d16de7ccbfc94963ae5ffc428e4c804f",
            "3f1125b92c5d4f8e970916e43aee47b1",
            "0ce716a83eb242708b23d5b7970f452c",
            "f716c292cad646ecaec1e075dd15252e",
            "f2eabd1f35844d56bbcccc6ba78e0be1",
            "d63f6b7d33dd4a5fa693eb3db19c4dea",
            "f329deb5e5014a17b17fbcc5a03eadfd",
            "6dbb3260140b415eb4de49801f2ac03c",
            "b89bdf978af3496b99a2af6e4b8b7bfa",
            "34144b4a2b06438cab9282d307006d79"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", \n",
        "    num_labels = 2,          \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca6c96f06abc4bb18ac400b5e0474ab2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ce716a83eb242708b23d5b7970f452c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_-2c_fGqYRM"
      },
      "source": [
        "## Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhTFyn0Np7g1"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr = 2e-5,  eps = 1e-8 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqvo-DulqvpX"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWgxvzQcrFvl"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AalsJBLZq_it"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie072hj6rii2"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    elapsed_rounded = int(round((elapsed)))    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWfMHMQTrt6x",
        "outputId": "35b1472f-d6c6-4c1e-f2df-fc784db0d5e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 13\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "         \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:34.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:51.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:07.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:24.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:41.\n",
            "\n",
            "  Average training loss: 0.49\n",
            "  Training epcoh took: 0:01:41\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:34.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:51.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:08.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:25.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:42.\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epcoh took: 0:01:42\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:34.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:51.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:09.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:26.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:43.\n",
            "\n",
            "  Average training loss: 0.19\n",
            "  Training epcoh took: 0:01:43\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:34.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:52.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:09.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:26.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:43.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Training epcoh took: 0:01:43\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl1Y1m6tt7Ld",
        "outputId": "b8128b84-9d9c-46c3-8c06-0fb6f40eef03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show();"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLdAEjk6yXx6"
      },
      "source": [
        "# Performance in test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7mJzlQQykKm"
      },
      "source": [
        "Matthew's correlation coefficient is the metric used by the wider NLP community to evaluate performance on CoLA. With this metric, +1 is the best score, and -1 is the worst score. This way, we can see how well we perform this specific task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4vK02MEy_Hh"
      },
      "source": [
        "## Test data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZLJnT7fyj3D",
        "outputId": "89234c25-370a-4938-d663-641a671b9e8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "\n",
        "for sent in sentences:\n",
        "\n",
        "    encoded_sent = tokenizer.encode(sent, add_special_tokens = True)\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3NIjPLpx61i"
      },
      "source": [
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsgg79TEzuUF",
        "outputId": "af2d950a-2a3a-48ac-d31b-34d954b9023b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "\n",
        "\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsKpRfCM0aTD",
        "outputId": "4a780b93-dd13-4394-f022-dc024a4131a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# scores for individual batches\n",
        "matthews_set"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.14856415213808927,\n",
              " -0.2548235957188128,\n",
              " 0.4040950971038548,\n",
              " 0.34151450937027694,\n",
              " 0.32328707534629597,\n",
              " 0.7410010097502685,\n",
              " 0.5555555555555556,\n",
              " 0.0,\n",
              " 0.8320502943378436,\n",
              " 0.7704873741021288,\n",
              " 0.7679476477883045,\n",
              " 0.5465943944999485,\n",
              " 0.7562449037944323,\n",
              " 0.7125253031944253,\n",
              " 0.2342878320018382,\n",
              " 0.49382916465843113,\n",
              " 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krmZSGqd0f0B",
        "outputId": "02ada881-5b0a-4ef1-e519-6c1535443ca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiIhTzaQ1jYm"
      },
      "source": [
        "# Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3jnE3cU1eOo",
        "outputId": "37977f4a-28b4-4469-efa6-e095b15021f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import os\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/vocab.txt',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0OyQwKh1v-u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}